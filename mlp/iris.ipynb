{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4521hI3NLpNGtaNtzne9e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgcvale/pytorch-playground/blob/main/iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QCC_TmDPvWXc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# architecture:\n",
        "\n",
        "\"\"\"\n",
        "Dense(12, input_dim=x_train.shape[1] -> 4),\n",
        "ReLU(),\n",
        "Dense(6),\n",
        "ReLU(),\n",
        "Dense(3),\n",
        "Softmax()\n",
        "\"\"\"\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, in_features=4, h1=12, h2=6, out_features=3):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(in_features, h1) # first layer (input to 12)\n",
        "    self.fc2 = nn.Linear(h1, h2) # second layer (12 to 6)\n",
        "    self.out = nn.Linear(h2, out_features) # third layer (6 to 3 softmax); softmax is implicit\n",
        "\n",
        "  def forward(self, x):\n",
        "    # feed through the layers\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "poXijEsmvvBd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, model, save_best_weights=True, patience=6, min_delta=0.01, mode='min', min_epochs=5):\n",
        "        if mode not in {\"min\", \"max\"}:\n",
        "            raise ValueError(f\"Invalid mode '{mode}'. Must be 'min' or 'max'.\")\n",
        "        if model is None:\n",
        "            raise ValueError(\"The model must be provided.\")\n",
        "        if patience <= 0:\n",
        "            raise ValueError(\"Patience must be at least 1.\")\n",
        "\n",
        "        self.model = model\n",
        "        self.save_best_weights = save_best_weights\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.mode = mode\n",
        "        self.best_score = None\n",
        "        self.counter = 0\n",
        "        self.best_weights = None\n",
        "        self.best_epoch = -1\n",
        "        self.current_epoch = 0\n",
        "        self.min_epochs = min_epochs\n",
        "        self.should_stop = False  # Flag to indicate early stopping\n",
        "\n",
        "    def step(self, current_score):\n",
        "        self.current_epoch += 1\n",
        "        if self.best_score is None:\n",
        "            improved = True\n",
        "        elif self.mode == 'min':\n",
        "            improved = current_score < self.best_score - self.min_delta\n",
        "        else:  # mode == 'max'\n",
        "            improved = current_score > self.best_score + self.min_delta\n",
        "\n",
        "        if improved:\n",
        "            self.best_score = current_score\n",
        "            if self.save_best_weights:\n",
        "                self.best_weights = copy.deepcopy(self.model.state_dict())\n",
        "                self.best_epoch = self.current_epoch\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience and self.current_epoch >= self.min_epochs:\n",
        "                self.should_stop = True  # Set flag instead of loading weights\n",
        "        return self.should_stop"
      ],
      "metadata": {
        "id": "mFLsRUXXJ3rL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7esRScaNXLV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Iris.csv')\n",
        "df.drop('Id', inplace=True, axis=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Z06nCeji0hbx",
        "outputId": "92ca855c-c2ba-4353-89a9-bac8f1a5252e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
              "0              5.1           3.5            1.4           0.2     Iris-setosa\n",
              "1              4.9           3.0            1.4           0.2     Iris-setosa\n",
              "2              4.7           3.2            1.3           0.2     Iris-setosa\n",
              "3              4.6           3.1            1.5           0.2     Iris-setosa\n",
              "4              5.0           3.6            1.4           0.2     Iris-setosa\n",
              "..             ...           ...            ...           ...             ...\n",
              "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
              "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
              "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
              "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
              "149            5.9           3.0            5.1           1.8  Iris-virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e828bca-0cb9-4c70-b8f0-e4c4981e24ce\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e828bca-0cb9-4c70-b8f0-e4c4981e24ce')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e828bca-0cb9-4c70-b8f0-e4c4981e24ce button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e828bca-0cb9-4c70-b8f0-e4c4981e24ce');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f4e57b67-4fa8-48c7-93e8-6cfba51e645f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4e57b67-4fa8-48c7-93e8-6cfba51e645f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f4e57b67-4fa8-48c7-93e8-6cfba51e645f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_33d2d9db-1fec-48e5-b8c4-73836b004267\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_33d2d9db-1fec-48e5-b8c4-73836b004267 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"SepalLengthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SepalWidthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4335943113621737,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PetalLengthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7644204199522617,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PetalWidthCm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7631607417008414,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Iris-setosa\",\n          \"Iris-versicolor\",\n          \"Iris-virginica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('Species', axis=1)\n",
        "y = pd.Categorical(df['Species']).codes"
      ],
      "metadata": {
        "id": "zJhKjEu41UN4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(x.values)\n",
        "x = pd.DataFrame(scaled, columns=x.columns)"
      ],
      "metadata": {
        "id": "ou2RyYUN1gFK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.values"
      ],
      "metadata": {
        "id": "j-2gFazV2XDh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "uKFzrgxI2bUJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that the data is all good to go, we can define the loss function (crossentropyloss due to multiclass classification), optimizer, lr and other hyperparameters\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "model = Model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0015)\n",
        "early_stopping = EarlyStopping(model, save_best_weights=True, patience=6, min_delta=0.012, mode='min', min_epochs=40)\n",
        "\n",
        "epochs = 300\n",
        "losses = []\n",
        "\n",
        "# actually train the model\n",
        "for i in range(epochs):\n",
        "  # forward pass\n",
        "  model.train()\n",
        "  y_pred = model(x_train)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pred_classes = torch.argmax(y_pred, dim=1).cpu().numpy()\n",
        "    true_classes = y_train.cpu().numpy()\n",
        "    f1 = f1_score(true_classes, pred_classes, average='weighted')\n",
        "\n",
        "  print(f\"[EPOCH {i}] - Loss: {loss} - F1: {f1}\")\n",
        "\n",
        "  if early_stopping.step(loss.item()):\n",
        "      print(f\"[EPOCH {i}] - STOPPED DUE TO EARLY STOPPING; BEST EPOCH WAS {early_stopping.best_epoch}\")\n",
        "      break\n",
        "\n",
        "  optimizer.zero_grad() # reset the error gradient from the previous backpropagation\n",
        "  loss.backward() # calculate the new error gradient through backpropagation\n",
        "  optimizer.step() # update model params based on backpropagation gradient\n",
        "\n",
        "\n",
        "if early_stopping.best_weights is not None:\n",
        "    model.load_state_dict(early_stopping.best_weights)\n",
        "    print(f\"Loaded best weights from epoch {early_stopping.best_epoch}\")\n",
        "\n",
        "model.eval()\n",
        "# see the final accuracy on the test dataset\n",
        "with torch.no_grad():\n",
        "  y_test_pred = model.forward(x_test)\n",
        "  pred_classes = torch.argmax(y_test_pred, dim=1).cpu().numpy()\n",
        "\n",
        "  f1 = f1_score(y_test, pred_classes, average='weighted')\n",
        "  true_classes = y_test.cpu().numpy()\n",
        "  loss = criterion(y_test_pred, y_test)\n",
        "\n",
        "print(f\"\\TEST PREDICTIONS: {pred_classes}, TRUE TEST VALUES: {y_test}\")\n",
        "print(f\"FINAL LOSS: {loss} - FINAL F1: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9v5O3Vl2iQz",
        "outputId": "dd59216d-52e7-42a5-f1ee-5ea98ada3582"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH 0] - Loss: 1.1309696435928345 - F1: 0.3077717019822283\n",
            "[EPOCH 1] - Loss: 1.1286275386810303 - F1: 0.3194451871657754\n",
            "[EPOCH 2] - Loss: 1.1263309717178345 - F1: 0.3194451871657754\n",
            "[EPOCH 3] - Loss: 1.124078392982483 - F1: 0.31823490378234903\n",
            "[EPOCH 4] - Loss: 1.1218390464782715 - F1: 0.3475939269171384\n",
            "[EPOCH 5] - Loss: 1.1196067333221436 - F1: 0.36583333333333334\n",
            "[EPOCH 6] - Loss: 1.1173896789550781 - F1: 0.38313895781637713\n",
            "[EPOCH 7] - Loss: 1.1151710748672485 - F1: 0.3927128427128427\n",
            "[EPOCH 8] - Loss: 1.1129653453826904 - F1: 0.40482165404040404\n",
            "[EPOCH 9] - Loss: 1.1107747554779053 - F1: 0.4364966299019608\n",
            "[EPOCH 10] - Loss: 1.1085807085037231 - F1: 0.4586046948356807\n",
            "[EPOCH 11] - Loss: 1.106361746788025 - F1: 0.4624226842536701\n",
            "[EPOCH 12] - Loss: 1.104142665863037 - F1: 0.4676277802327294\n",
            "[EPOCH 13] - Loss: 1.1019190549850464 - F1: 0.4676277802327294\n",
            "[EPOCH 14] - Loss: 1.0996673107147217 - F1: 0.4658408408408409\n",
            "[EPOCH 15] - Loss: 1.0974055528640747 - F1: 0.46417486338797814\n",
            "[EPOCH 16] - Loss: 1.0950876474380493 - F1: 0.47502157031924075\n",
            "[EPOCH 17] - Loss: 1.092738389968872 - F1: 0.4819362455726092\n",
            "[EPOCH 18] - Loss: 1.0903795957565308 - F1: 0.4819362455726092\n",
            "[EPOCH 19] - Loss: 1.0880006551742554 - F1: 0.4819362455726092\n",
            "[EPOCH 20] - Loss: 1.0855977535247803 - F1: 0.4887500000000001\n",
            "[EPOCH 21] - Loss: 1.0831674337387085 - F1: 0.48675213675213674\n",
            "[EPOCH 22] - Loss: 1.0807133913040161 - F1: 0.4854359405663022\n",
            "[EPOCH 23] - Loss: 1.0782239437103271 - F1: 0.4854359405663022\n",
            "[EPOCH 24] - Loss: 1.0756852626800537 - F1: 0.4854359405663022\n",
            "[EPOCH 25] - Loss: 1.0731127262115479 - F1: 0.49861111111111106\n",
            "[EPOCH 26] - Loss: 1.0705044269561768 - F1: 0.5050876279715426\n",
            "[EPOCH 27] - Loss: 1.067872405052185 - F1: 0.5114964008859357\n",
            "[EPOCH 28] - Loss: 1.0652233362197876 - F1: 0.5178419799109455\n",
            "[EPOCH 29] - Loss: 1.0625393390655518 - F1: 0.5178419799109455\n",
            "[EPOCH 30] - Loss: 1.0598149299621582 - F1: 0.5218544745484401\n",
            "[EPOCH 31] - Loss: 1.0570470094680786 - F1: 0.5218544745484401\n",
            "[EPOCH 32] - Loss: 1.0542373657226562 - F1: 0.5218544745484401\n",
            "[EPOCH 33] - Loss: 1.051369547843933 - F1: 0.5218544745484401\n",
            "[EPOCH 34] - Loss: 1.0484395027160645 - F1: 0.5247294372294372\n",
            "[EPOCH 35] - Loss: 1.045451045036316 - F1: 0.5310777069204036\n",
            "[EPOCH 36] - Loss: 1.0424200296401978 - F1: 0.5310777069204036\n",
            "[EPOCH 37] - Loss: 1.0393340587615967 - F1: 0.5310777069204036\n",
            "[EPOCH 38] - Loss: 1.0361907482147217 - F1: 0.5310777069204036\n",
            "[EPOCH 39] - Loss: 1.0329972505569458 - F1: 0.5301515151515152\n",
            "[EPOCH 40] - Loss: 1.02975332736969 - F1: 0.5301515151515152\n",
            "[EPOCH 41] - Loss: 1.0264613628387451 - F1: 0.5301515151515152\n",
            "[EPOCH 42] - Loss: 1.0231236219406128 - F1: 0.5301515151515152\n",
            "[EPOCH 43] - Loss: 1.019738793373108 - F1: 0.5301515151515152\n",
            "[EPOCH 44] - Loss: 1.016300082206726 - F1: 0.5301515151515152\n",
            "[EPOCH 45] - Loss: 1.0127934217453003 - F1: 0.5293359545653123\n",
            "[EPOCH 46] - Loss: 1.0092273950576782 - F1: 0.5293359545653123\n",
            "[EPOCH 47] - Loss: 1.0056073665618896 - F1: 0.5293359545653123\n",
            "[EPOCH 48] - Loss: 1.0019333362579346 - F1: 0.5293359545653123\n",
            "[EPOCH 49] - Loss: 0.998187243938446 - F1: 0.5293359545653123\n",
            "[EPOCH 50] - Loss: 0.9943885207176208 - F1: 0.5293359545653123\n",
            "[EPOCH 51] - Loss: 0.9905334115028381 - F1: 0.5293359545653123\n",
            "[EPOCH 52] - Loss: 0.9866166710853577 - F1: 0.5293359545653123\n",
            "[EPOCH 53] - Loss: 0.9826440811157227 - F1: 0.5293359545653123\n",
            "[EPOCH 54] - Loss: 0.9786068797111511 - F1: 0.547918010926141\n",
            "[EPOCH 55] - Loss: 0.9745038151741028 - F1: 0.547918010926141\n",
            "[EPOCH 56] - Loss: 0.970340371131897 - F1: 0.5657691737130989\n",
            "[EPOCH 57] - Loss: 0.9661111235618591 - F1: 0.5657691737130989\n",
            "[EPOCH 58] - Loss: 0.9618165493011475 - F1: 0.5657691737130989\n",
            "[EPOCH 59] - Loss: 0.9574533700942993 - F1: 0.5657691737130989\n",
            "[EPOCH 60] - Loss: 0.9530112147331238 - F1: 0.5657691737130989\n",
            "[EPOCH 61] - Loss: 0.9485071897506714 - F1: 0.5657691737130989\n",
            "[EPOCH 62] - Loss: 0.9439547061920166 - F1: 0.5657691737130989\n",
            "[EPOCH 63] - Loss: 0.9393455386161804 - F1: 0.5829446916985311\n",
            "[EPOCH 64] - Loss: 0.9346601963043213 - F1: 0.5829446916985311\n",
            "[EPOCH 65] - Loss: 0.9299124479293823 - F1: 0.5829446916985311\n",
            "[EPOCH 66] - Loss: 0.9251125454902649 - F1: 0.5829446916985311\n",
            "[EPOCH 67] - Loss: 0.9202579855918884 - F1: 0.5994949494949495\n",
            "[EPOCH 68] - Loss: 0.9153455495834351 - F1: 0.5994949494949495\n",
            "[EPOCH 69] - Loss: 0.910386323928833 - F1: 0.6154660154660154\n",
            "[EPOCH 70] - Loss: 0.9053870439529419 - F1: 0.6309001185953487\n",
            "[EPOCH 71] - Loss: 0.9003342390060425 - F1: 0.6309001185953487\n",
            "[EPOCH 72] - Loss: 0.8952224254608154 - F1: 0.6613147400700581\n",
            "[EPOCH 73] - Loss: 0.8900514841079712 - F1: 0.6613147400700581\n",
            "[EPOCH 74] - Loss: 0.884828507900238 - F1: 0.6613147400700581\n",
            "[EPOCH 75] - Loss: 0.8795573115348816 - F1: 0.6613147400700581\n",
            "[EPOCH 76] - Loss: 0.8742455840110779 - F1: 0.6613147400700581\n",
            "[EPOCH 77] - Loss: 0.8688852190971375 - F1: 0.6622838875179374\n",
            "[EPOCH 78] - Loss: 0.8634786605834961 - F1: 0.6622838875179374\n",
            "[EPOCH 79] - Loss: 0.8580248951911926 - F1: 0.6622838875179374\n",
            "[EPOCH 80] - Loss: 0.8525488376617432 - F1: 0.6760420380273321\n",
            "[EPOCH 81] - Loss: 0.8470467329025269 - F1: 0.6760420380273321\n",
            "[EPOCH 82] - Loss: 0.8415109515190125 - F1: 0.6894141987728185\n",
            "[EPOCH 83] - Loss: 0.8359442353248596 - F1: 0.6894141987728185\n",
            "[EPOCH 84] - Loss: 0.8303375840187073 - F1: 0.6894141987728185\n",
            "[EPOCH 85] - Loss: 0.8246926069259644 - F1: 0.6894141987728185\n",
            "[EPOCH 86] - Loss: 0.8190017342567444 - F1: 0.6894141987728185\n",
            "[EPOCH 87] - Loss: 0.8132789731025696 - F1: 0.6894141987728185\n",
            "[EPOCH 88] - Loss: 0.8075287938117981 - F1: 0.6894141987728185\n",
            "[EPOCH 89] - Loss: 0.8017471432685852 - F1: 0.6894141987728185\n",
            "[EPOCH 90] - Loss: 0.7959350347518921 - F1: 0.6900721208023438\n",
            "[EPOCH 91] - Loss: 0.7900899648666382 - F1: 0.6900721208023438\n",
            "[EPOCH 92] - Loss: 0.7841994762420654 - F1: 0.6900721208023438\n",
            "[EPOCH 93] - Loss: 0.7782741785049438 - F1: 0.7030320140767393\n",
            "[EPOCH 94] - Loss: 0.7723225355148315 - F1: 0.7030320140767393\n",
            "[EPOCH 95] - Loss: 0.7663605809211731 - F1: 0.7030320140767393\n",
            "[EPOCH 96] - Loss: 0.7603726983070374 - F1: 0.7030320140767393\n",
            "[EPOCH 97] - Loss: 0.7543776035308838 - F1: 0.7030320140767393\n",
            "[EPOCH 98] - Loss: 0.7483799457550049 - F1: 0.7030320140767393\n",
            "[EPOCH 99] - Loss: 0.7423593997955322 - F1: 0.7030320140767393\n",
            "[EPOCH 100] - Loss: 0.7363095879554749 - F1: 0.7030320140767393\n",
            "[EPOCH 101] - Loss: 0.730241596698761 - F1: 0.7030320140767393\n",
            "[EPOCH 102] - Loss: 0.7241744995117188 - F1: 0.7163379007931509\n",
            "[EPOCH 103] - Loss: 0.7180975079536438 - F1: 0.7163379007931509\n",
            "[EPOCH 104] - Loss: 0.7119982838630676 - F1: 0.7163379007931509\n",
            "[EPOCH 105] - Loss: 0.7058906555175781 - F1: 0.7163379007931509\n",
            "[EPOCH 106] - Loss: 0.6997776031494141 - F1: 0.7163379007931509\n",
            "[EPOCH 107] - Loss: 0.6936670541763306 - F1: 0.7163379007931509\n",
            "[EPOCH 108] - Loss: 0.6875762939453125 - F1: 0.7163379007931509\n",
            "[EPOCH 109] - Loss: 0.6815136075019836 - F1: 0.7293561839844115\n",
            "[EPOCH 110] - Loss: 0.6754776239395142 - F1: 0.7293561839844115\n",
            "[EPOCH 111] - Loss: 0.6694707274436951 - F1: 0.7293561839844115\n",
            "[EPOCH 112] - Loss: 0.6634981632232666 - F1: 0.7293561839844115\n",
            "[EPOCH 113] - Loss: 0.6575683951377869 - F1: 0.7421097466889547\n",
            "[EPOCH 114] - Loss: 0.6516939997673035 - F1: 0.7421097466889547\n",
            "[EPOCH 115] - Loss: 0.6458765268325806 - F1: 0.7421097466889547\n",
            "[EPOCH 116] - Loss: 0.6401152014732361 - F1: 0.7546201780246872\n",
            "[EPOCH 117] - Loss: 0.634408175945282 - F1: 0.7546201780246872\n",
            "[EPOCH 118] - Loss: 0.6287840604782104 - F1: 0.7546201780246872\n",
            "[EPOCH 119] - Loss: 0.6232522130012512 - F1: 0.7430925126531079\n",
            "[EPOCH 120] - Loss: 0.6178052425384521 - F1: 0.7430925126531079\n",
            "[EPOCH 121] - Loss: 0.6124393939971924 - F1: 0.7430925126531079\n",
            "[EPOCH 122] - Loss: 0.6071678400039673 - F1: 0.7430925126531079\n",
            "[EPOCH 123] - Loss: 0.6019788980484009 - F1: 0.7430925126531079\n",
            "[EPOCH 124] - Loss: 0.5968648791313171 - F1: 0.7430925126531079\n",
            "[EPOCH 125] - Loss: 0.5918349623680115 - F1: 0.7430925126531079\n",
            "[EPOCH 126] - Loss: 0.5868732929229736 - F1: 0.7556916262439936\n",
            "[EPOCH 127] - Loss: 0.5819883942604065 - F1: 0.7556916262439936\n",
            "[EPOCH 128] - Loss: 0.5772027373313904 - F1: 0.7556916262439936\n",
            "[EPOCH 129] - Loss: 0.5725015997886658 - F1: 0.7556916262439936\n",
            "[EPOCH 130] - Loss: 0.5678814053535461 - F1: 0.7556916262439936\n",
            "[EPOCH 131] - Loss: 0.56333327293396 - F1: 0.7778819736473227\n",
            "[EPOCH 132] - Loss: 0.558860719203949 - F1: 0.7778819736473227\n",
            "[EPOCH 133] - Loss: 0.5544854998588562 - F1: 0.7778819736473227\n",
            "[EPOCH 134] - Loss: 0.5502309799194336 - F1: 0.7896861268047708\n",
            "[EPOCH 135] - Loss: 0.5460532903671265 - F1: 0.7896861268047708\n",
            "[EPOCH 136] - Loss: 0.5419698357582092 - F1: 0.7896861268047708\n",
            "[EPOCH 137] - Loss: 0.5379737019538879 - F1: 0.7896861268047708\n",
            "[EPOCH 138] - Loss: 0.5340648889541626 - F1: 0.7896861268047708\n",
            "[EPOCH 139] - Loss: 0.5302363634109497 - F1: 0.7896861268047708\n",
            "[EPOCH 140] - Loss: 0.526495635509491 - F1: 0.7896861268047708\n",
            "[EPOCH 141] - Loss: 0.5228267908096313 - F1: 0.7896861268047708\n",
            "[EPOCH 142] - Loss: 0.5192385911941528 - F1: 0.7896861268047708\n",
            "[EPOCH 143] - Loss: 0.5157136917114258 - F1: 0.7896861268047708\n",
            "[EPOCH 144] - Loss: 0.5122501254081726 - F1: 0.7896861268047708\n",
            "[EPOCH 145] - Loss: 0.5088450312614441 - F1: 0.7896861268047708\n",
            "[EPOCH 146] - Loss: 0.505498468875885 - F1: 0.7896861268047708\n",
            "[EPOCH 147] - Loss: 0.5022162795066833 - F1: 0.7896861268047708\n",
            "[EPOCH 148] - Loss: 0.49899324774742126 - F1: 0.7896861268047708\n",
            "[EPOCH 149] - Loss: 0.4958325922489166 - F1: 0.7896861268047708\n",
            "[EPOCH 150] - Loss: 0.4927220046520233 - F1: 0.7896861268047708\n",
            "[EPOCH 151] - Loss: 0.48966535925865173 - F1: 0.7896861268047708\n",
            "[EPOCH 152] - Loss: 0.48665720224380493 - F1: 0.7896861268047708\n",
            "[EPOCH 153] - Loss: 0.48368746042251587 - F1: 0.7896861268047708\n",
            "[EPOCH 154] - Loss: 0.4807623624801636 - F1: 0.7896861268047708\n",
            "[EPOCH 155] - Loss: 0.4778866469860077 - F1: 0.7896861268047708\n",
            "[EPOCH 156] - Loss: 0.47506099939346313 - F1: 0.7896861268047708\n",
            "[EPOCH 157] - Loss: 0.47227635979652405 - F1: 0.7896861268047708\n",
            "[EPOCH 158] - Loss: 0.4695318639278412 - F1: 0.7896861268047708\n",
            "[EPOCH 159] - Loss: 0.46682509779930115 - F1: 0.7896861268047708\n",
            "[EPOCH 160] - Loss: 0.4641555845737457 - F1: 0.7896861268047708\n",
            "[EPOCH 161] - Loss: 0.4615195691585541 - F1: 0.7896861268047708\n",
            "[EPOCH 162] - Loss: 0.45892396569252014 - F1: 0.7896861268047708\n",
            "[EPOCH 163] - Loss: 0.45636433362960815 - F1: 0.7896861268047708\n",
            "[EPOCH 164] - Loss: 0.45383962988853455 - F1: 0.8001683501683502\n",
            "[EPOCH 165] - Loss: 0.45134687423706055 - F1: 0.8104537625614907\n",
            "[EPOCH 166] - Loss: 0.44888538122177124 - F1: 0.8104537625614907\n",
            "[EPOCH 167] - Loss: 0.4464530050754547 - F1: 0.8104537625614907\n",
            "[EPOCH 168] - Loss: 0.44405397772789 - F1: 0.8104537625614907\n",
            "[EPOCH 169] - Loss: 0.4416850805282593 - F1: 0.8104537625614907\n",
            "[EPOCH 170] - Loss: 0.43936625123023987 - F1: 0.8104537625614907\n",
            "[EPOCH 171] - Loss: 0.4370761811733246 - F1: 0.8104537625614907\n",
            "[EPOCH 172] - Loss: 0.4348025321960449 - F1: 0.8104537625614907\n",
            "[EPOCH 173] - Loss: 0.43255531787872314 - F1: 0.8104537625614907\n",
            "[EPOCH 174] - Loss: 0.43035489320755005 - F1: 0.8104537625614907\n",
            "[EPOCH 175] - Loss: 0.42816799879074097 - F1: 0.8104537625614907\n",
            "[EPOCH 176] - Loss: 0.42601823806762695 - F1: 0.8104537625614907\n",
            "[EPOCH 177] - Loss: 0.423896849155426 - F1: 0.8215930162387537\n",
            "[EPOCH 178] - Loss: 0.4217996299266815 - F1: 0.8215930162387537\n",
            "[EPOCH 179] - Loss: 0.4197155237197876 - F1: 0.8215930162387537\n",
            "[EPOCH 180] - Loss: 0.4176495671272278 - F1: 0.8215930162387537\n",
            "[EPOCH 181] - Loss: 0.41560274362564087 - F1: 0.8314661743849887\n",
            "[EPOCH 182] - Loss: 0.4135752320289612 - F1: 0.8314661743849887\n",
            "[EPOCH 183] - Loss: 0.4115644097328186 - F1: 0.8411805555555556\n",
            "[EPOCH 184] - Loss: 0.4095698893070221 - F1: 0.8411805555555556\n",
            "[EPOCH 185] - Loss: 0.40759173035621643 - F1: 0.8507481443994602\n",
            "[EPOCH 186] - Loss: 0.40563222765922546 - F1: 0.8507481443994602\n",
            "[EPOCH 187] - Loss: 0.40369635820388794 - F1: 0.8507481443994602\n",
            "[EPOCH 188] - Loss: 0.40177664160728455 - F1: 0.8507481443994602\n",
            "[EPOCH 189] - Loss: 0.39987069368362427 - F1: 0.8507481443994602\n",
            "[EPOCH 190] - Loss: 0.39797815680503845 - F1: 0.8601803943692242\n",
            "[EPOCH 191] - Loss: 0.396104633808136 - F1: 0.8601803943692242\n",
            "[EPOCH 192] - Loss: 0.3942609429359436 - F1: 0.8694882776975338\n",
            "[EPOCH 192] - STOPPED DUE TO EARLY STOPPING; BEST EPOCH WAS 187\n",
            "Loaded best weights from epoch 187\n",
            "\\TEST PREDICTIONS: [0 0 0 1 0 2 0 1 2 0 0 2 0 0 2 1 1 2 2 1 2 0 1 2 2 2 1 0 1 1], TRUE TEST VALUES: tensor([0, 0, 0, 1, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2,\n",
            "        2, 2, 1, 0, 1, 1])\n",
            "FINAL LOSS: 0.3547094762325287 - FINAL F1: 0.9666666666666667\n"
          ]
        }
      ]
    }
  ]
}